---
title: "Progress Check 1 Review Session"
author:
  - Elizabeth King
  - Kevin Middleton
format:
  revealjs:
    theme: [default, custom.scss]
    standalone: true
    self-contained: true
    logo: QMLS_Logo.png
    slide-number: true
    show-slide-number: all
code-annotations: hover
bibliography: QMLS_Bibliography.bib
csl: evolution.csl
---

```{r setup}
#| message: false

library(tidyverse)
library(cowplot)
theme_set(theme_cowplot())

library(palmerpenguins)
island_data <- tibble(
  island = as.character(levels(penguins$island)),
  latitude = c(-64.766667, -65.433333, -64.733333),
  longitude = c( -64.083333, -65.5, -64.233333)
)
```


## Topics for Today

1. Best practices for coding & learning
2. Miscellaneous questions
3. Tidyverse functions
4. Data visualization
5. Probability
6. Progress Check 1 Questions


## Best practices for coding & learning

> What's going to be the best option for reproducibility vs "reading the code" in the step-by-step way. 

> Important points to consider when writing code in R in general and with respect to drawing bar charts, boxplots etc.


## Best practices for coding & learning

> I have the basics, but a lot of times the problem sets ask for more and it's a bit hard to understand even with outside help (internet, R help, etc.)

> ... (and this is a bit more philosophical) is there a "right" answer? Although you said at the beginning of the semester that there are many ways to do the same operation in R, it does seem like there are particular ways you would prefer us to do things in opposition to that. Could you be explicit about where we can have freedom to experiment and where you want "your" answer?


## Best practices for coding & learning

Many people have advice & resources
Let's look at some code


## Strategies for Learning R {.smaller}

1. Time. Practice. 
2. Using help files
    - ?unique
3. Tips
    - Make your own Help folder 
    - Develop a system for saving resources
    - Write pseudocode & use comments
    - Growth mindset
3. Extra Resources
    - For learning R & lots of other stuff (like Git)


## Miscellaneous questions

> How do we deal with numbers that are considered chr in R?  Like doing analysis/mathematical functions and stuff.

```{r}
#| echo: true

myVector <- c(4,5,2,1,"h",6, "3")
str(myVector)
str(as.numeric(myVector))

```


## Miscellaneous questions

> How do we go about changing a column of data if there is an unwanted variable in them?


## Miscellaneous questions

> How would we determine the right number of samples for a study for it to be statistically significant? 

- Stay tuned for power analysis (Unit 11)


## Miscellaneous questions

> What are the limitations associated with applying Bayesian approaches in the context of large-scale omics data analysis, including issues related to data sparsity, model complexity, and computational scalability?


## Miscellaneous questions

> Refresher on how to find and recategorize outliers.

-add example


## Miscellaneous questions

> Can you show an example of how to determine if your dataset follows a normal (or other) distribution?


## Tests of normality

```{r}
#| echo: true

set.seed(93847)
x <- rnorm(5000)
ggplot(tibble(x), aes(x)) +
  geom_histogram(bins = 30)
```


## Tests of normality

```{r}
#| echo: true
shapiro.test(x)
```


## Tests of normality

```{r}
#| echo: true

set.seed(423479)
x <- runif(500)
ggplot(tibble(x), aes(x)) +
  geom_histogram(bins = 30)
```


## Tests of normality

```{r}
#| echo: true

shapiro.test(x)
```


## Tests of normality

```{r}
#| echo: true

set.seed(347)
x <- runif(15)
ggplot(tibble(x), aes(x)) +
  geom_histogram(bins = 30)
```


## Tests of normality

```{r}
#| echo: true

shapiro.test(x)
```


## Set seed

> How does the set.seed() function work? I understand that setting a seed at the beginning of the chunk allows for the random numbers being generated to be consistent each time you run the code, but how does this actually work?

`?set.seed()`


## Set seed {.smaller}

> I had trouble with the set.seed() in problem set 4, may you show a similar example in class review. 

```{r}
#| echo: true

set.seed(34235)
AA <- rnorm(3); BB <- rnorm(3)
AA
BB

set.seed(34235)
AA <- rnorm(3)

set.seed(34235)
BB <- rnorm(3)
AA 
BB
```


## Tidyverse functions

> I would like to better understand when I should be pivoting my data. ...  I am still unsure of when data needs to be pivotted if I am given a dataset and left to my own devices. Is it good practice to immediately convert wide data into long and then convert it back again after final analyses or transformations? Or are there certain functions which require the long data format, and if so, how can I identify them?

> I'm still a bit confused about joining tables. Specifically, when do I need to pivot my data frames before joining or is that something I always do?


## Tidyverse functions

> I don't understand the selection process for grouping compared to filtering. The 2nd activity in the PS-04 where we're meant to assign the variables in the 1st activity and then change only one value each time. I couldn't figure out how to change one variable without retyping the whole thing; and that makes the outputs different but I feel its inefficient. General question about what I should be thinking when I know I'm going to need this data later.


## Tidyverse: pivots

> Why is it good data practice to keep my data in a bunch of smaller tables that I join together?

> When making clean data, what is the best way to determine whether or not you need to make it longer or wider at a quick glance of the data.


## Pivots

Shape of your data:

- Wide: rows have multiple columns with values
- Long: rows have 1 column with values


## Wide data

Most common for data entry:

```{r}
#| echo: true

library(palmerpenguins)
head(penguins)
```

Each row is a logical unit (e.g., sample, individual)


## Wide data

```{r}
#| echo: true

island_data
```


## Long data

- Truly "tidy"
- Frequently impractical for data entry (lot of repeated values)
- Often useful for plotting
    - Column name becomes a value for a new variable
    - Cell value becomes the value for that new variable

`pivot_longer()`: wide $\rightarrow$ long

`pivot_wider()`: long $\rightarrow$ wide


## You want this plot

```{r}
penguins_long <- penguins |>
  select(species, sex, body_mass_g, bill_length_mm, bill_depth_mm) |> 
  pivot_longer(cols = -c(species, sex, body_mass_g),
               names_to = "bill_measure",
               values_to = "length") |> 
  drop_na()

ggplot(penguins_long, aes(x = body_mass_g, y = length, color = species)) +
  geom_point(size = 3) +
  scale_colour_viridis_d() +
  facet_grid(bill_measure ~ sex, scales = "free_y")
```


## You need

- `species`
- `sex`
- `body_mass_g`
- `bill_length_mm`
- `bill_depth_mm`

Turn `bill_length_mm` and `bill_depth_mm` into a new column "bill_measure" and values to a column called "length"


## `pivot_longer()`

```{r}
#| echo: true

penguins_long <- penguins |>
  select(species, sex, body_mass_g, bill_length_mm, bill_depth_mm) |> 
  pivot_longer(cols = c(bill_length_mm, bill_depth_mm),
               names_to = "bill_measure",
               values_to = "length") |> 
  drop_na()
```

or

```{r}
#| echo: true

penguins_long <- penguins |>
  select(species, sex, body_mass_g, bill_length_mm, bill_depth_mm) |> 
  pivot_longer(cols = -c(species, sex, body_mass_g),
               names_to = "bill_measure",
               values_to = "length") |> 
  drop_na()
```


## Long data

```{r}
#| echo: true

penguins_long
```


## Plot

```{r}
#| echo: true
#| output-location: slide

ggplot(penguins_long, aes(x = body_mass_g, y = length, color = species)) +
  geom_point(size = 3) +
  scale_colour_viridis_d() +
  facet_grid(bill_measure ~ sex, scales = "free_y")
```


## Edit values

```{r}
#| echo: true

penguins_long <- penguins_long |> 
  mutate(bill_measure = str_remove(bill_measure, "_mm"),
         bill_measure = str_remove(bill_measure, "bill_"))

head(penguins_long)
```


## `pivot_wider()`

Be careful:

```{r}
#| echo: true

penguins_long |> 
  pivot_wider(id_cols = c(species, sex, body_mass_g),
              names_from = bill_measure, values_from = length)
```


## What happened?

`species`, `sex`, and `body_mass_g` don't uniquely identify new rows

```{r}
#| echo: true

penguins_long |> 
  group_by(species, sex, body_mass_g) |> 
  tally()
```


## Tidyverse: joins

> Joining with three tibbles is a little challenging can you help with how you would start this? 

Always joining two tibbles/data.frames: `left_join(left_join(A, B), C)`

What rows do you want to keep?

- `left_join(x, y)`: includes all rows in x.
- `right_join(x, y)`: includes all rows in y.
- `inner_join(x, y)`: includes all rows in x *and* y.
- `full_join(x, y)`: includes all rows in x *or* y.


## Joining

You also have data about the penguins' islands:

```{r}
#| echo: true

island_data
```


## Which way to join?

1. Penguin data into island data
2. Island data into penguin data


## Keys

```{r}
#| echo: true

intersect(colnames(penguins), colnames(island_data))
```


## `left_join()`

```{r}
#| echo: true

left_join(penguins, island_data)
```


## Making new variables

```{r}
#| echo: true

penguins <- penguins |> 
  mutate(log_bill_length = log10(bill_length_mm),
         log_bill_depth = log10(bill_depth_mm))

str(penguins)
```


## Making new variables

```{r}
#| echo: true

penguins$log_body_mass <- log10(penguins$body_mass_g)

str(penguins)
```


## `group_by()` and `summarize()`

1. Split the data into some set of subgroups
2. Apply some function(s) to create new variable(s)
3. Recombine the sets

- Means by species
- Means by species and sex
- Means by species, sex, and island


## Summarizing {.smaller}

```{r}
#| echo: true

penguins |> 
  group_by(species, sex, island) |> 
  summarize(mean_log_mass = mean(log_body_mass),
            mean_log_bill_length = mean(log_bill_length),
            .groups = "drop")
```


## What happened? {.smaller}

- Some `sex` coded as `NA`

```{r}
#| echo: true

penguins |> 
  drop_na(sex) |> 
  group_by(species, sex, island) |> 
  summarize(mean_log_mass = mean(log_body_mass),
            mean_log_bill_length = mean(log_bill_length),
            .groups = "drop")
```


## Data visualization

> Although we have not gone in depth into graph making, how should we decide what graph best represents a data set?

> I might've missed this, but does R automatically generate a graph based on the type of dataset? I know from previous statistics courses that the data set depends on the graph. Are we going to learn more graph types? 

> Is this a specific order to ggplot arguments? I'm still a little confused on how to set "bins" for histograms


## Data visualization

> Not necessarily a question per se, but I would like to learn more about interpreting visualization of data in R.  We've learned about different types of plots and visualizations and the code to use, but I struggle sometimes in my own data to articulately describe what a plot is telling me.  This might be something we discuss further on in the course, but, as of right now, it's something that I've been struggling with. 

> Are there other graphing tips that you can provide as we navigate the different types and how to set up each one?


## Data visualization

> I face issues with ggplot questions. Just a review on that will be very helpful

> I always make very silly little mistakes when creating plots with ggplot. Could you guys give a few organized examples of what all needs to be included when making plots.  


## Working with aesthetics

```{r}
penguins <- penguins |> 
  drop_na(body_mass_g)
```

```{r}
#| echo: true

ggplot(penguins, aes(body_mass_g, fill = species)) +
  geom_density()
```


## Working with aesthetics

```{r}
#| echo: true

ggplot(penguins, aes(body_mass_g, fill = species)) +
  geom_density(alpha = 0.5)
```


## Working with aesthetics

```{r}
#| echo: true

penguins <- penguins |> 
  mutate(species_alpha = case_when(
    species == "Adelie" ~ 1,
    species == "Chinstrap" ~ 0.5,
    species == "Gentoo" ~ 0.25
  ))
penguins |> select(species, species_alpha) |> slice_sample(n = 10)
```


## Working with aesthetics

```{r}
#| echo: true

ggplot(penguins, aes(body_mass_g, fill = species,
                     alpha = species_alpha)) +
  geom_density()
```


## Working with aesthetics

```{r}
#| echo: true

library(ggridges)
ggplot(penguins, aes(x = body_mass_g, y = species, fill = species)) +
  geom_density_ridges(alpha = 0.5)
```


## Working with aesthetics

```{r}
#| echo: true

ggplot(penguins, aes(body_mass_g, color = species, fill = species)) +
  geom_histogram(bins = 30, alpha = 0.5)
```


## Working with aesthetics

```{r}
#| echo: true

ggplot(penguins, aes(log_bill_length, log_bill_depth, color = species,
                     size = log_body_mass)) +
  geom_point()
```


## Working with aesthetics

- color
- shape
- size
- linetype
- fill
- alpha
- text parameters

All are context-specific


## Progress check questions

> Regarding the activity that merges EVI and Soil Respiration, I would like to know more about creating the unique identifier column since I'm not sure how to create it or how it is can be used to merge the data.

> Also, is there an easier way to slice the NA values out of the Rattlesnake data. Is there a way to specify only odd or even rows in the data without numbering them one by one?


## Probability 

> Can you go through conditional probability one more time, an example similar to the HIV one?

> I'm still struggling a bit with probability. I have a tendency to overthink and overcomplicate probability which often times causes me to second guess myself and make mistakes.


## Probability 

> I  would like to know more about conditional probability and the equation related to it.

> What makes up a sufficient interpretation of a probability? I feel like I struggle to find the words to answer questions related to the interpretation of probabilities. I think covering some more examples of this would be helpful for me, though I will also return to previous lectures for review. 


## Temperature dependent sex determination

<center>
<img src="https://i.imgur.com/GBXvrf9.jpg" width="70%" />
</center>


## Temperature dependent sex determination

Above the critical temperature ($T_c$)

- $Pr[Female] = 0.8$
- $Pr[Male] = 0.2$

Below the critical temperature ($not~T_c$)

- $Pr[Female] = 0.5$
- $Pr[Male] = 0.5$


## How to *preferentially* collect female eggs?

You want to collect an egg from a nest and estimate what the temperature was in that nest when sex was determined.

- You want to preferentially collect from nests with large numbers of females
- The temperature now is not necessarily what it was (so you can't use a thermometer)

What is the probability that the nest was above $T_c$, given that you have collected a female egg?


## Variables

- $Pr[Female | Above~T_c] = 0.8$
- $Pr[Female | Below~T_c] = 0.5$


## Bayes' rule

$$Pr[A | B] = \frac{Pr[B | A] \cdot Pr[A]}{Pr[B]}$$

We want: *probability of $T_c$ given that we have observed a $Female$*

$$Pr[Above~T_c | Female]$$

So:

- $A$ is $Above~T_c$
- $B$ is $Female$


## Bayes' rule

$$Pr[Above~ T_c | F] = \frac{Pr[F | Above~T_c] \cdot Pr[Above~T_c]}{Pr[F]}$$

We have:

- $Pr[F | Above~T_c] = 0.8$

We need:

- $Pr[Above~T_c]$
- $Pr[F]$


## Estimating $Pr[Above~T_c]$?

Without any additional information about the distribution of $Above~T_c$ among nests:

$$Pr[Above~T_c] = 0.5$$

- Equal probability that a nest is above $T_c$ or below.
- Choose some other probability if we have *a priori* information.


## Bayes' rule

$$Pr[Above~T_c | F] = \frac{Pr[F | Above~T_c] \cdot Pr[Above~T_c]}{Pr[F]}$$

We have:

- $Pr[F | Above~T_c] = 0.8$
- $Pr[Above~T_c] = 0.5$

We need:

- $Pr[F]$


## Conditional probability

```{r}
#| fig-align: center

library(ggflowchart)

FC <- tribble(
  ~ from, ~ to,
  "Temperature", "Above Tc\n0.5",
  "Temperature", "Below Tc\n0.5",
  "Above Tc\n0.5", "Pr[Female]\n0.8",
  "Above Tc\n0.5", "Pr[Male]\n0.2",
  "Below Tc\n0.5", "Pr[Female]\n0.5",
  "Below Tc\n0.5", "Pr[Male]\n0.5",
  "Pr[Female]\n0.8", "Female\nAbove Tc",
  "Pr[Male]\n0.2", "Male\nAbove Tc",
  "Pr[Female]\n0.5", "Female\nBelow Tc",
  "Pr[Male]\n0.5", "Male\nBelow Tc"
)

ggflowchart(FC,
            horizontal = TRUE,
            arrow_size = 0.25,
            text_size = 4,
            x_nudge = 0.3,
            y_nudge = 0.3)
```

$Pr[F]$ is the sum of the two paths to Female.


## Bayes' rule

\begin{align}
Pr[F] = & Pr[F | Above~T_c] \cdot Pr[T_c] + \\
        & Pr[F | Below~ T_c] \cdot Pr[Below~T_c]
\end{align}

So:

\begin{align}
Pr[F] & = 0.5 \cdot 0.5 + 0.5 \cdot 0.8 \\
      & = 0.25 + 0.4 \\
      & = 0.65
\end{align}


## Bayes' rule

\begin{align}
Pr[Above~T_c | F] & = \frac{Pr[F | Above~T_c] \cdot Pr[Above~T_c]}{Pr[F]}\\
                  & = \frac{0.8 \cdot 0.5}{0.65} \\
                  & = \frac{0.40}{0.65} \\
                  & = 0.62
\end{align}

Given a female egg, the probability that the nest was above $T_c$ is 0.62.


## Solving with natural numbers

```{r}
FC2 <- tribble(
  ~ from, ~ to,
  "Temperature", "Above Tc\n0.5",
  "Temperature", "Below Tc\n0.5",
  "Below Tc\n0.5", "Pr[Male]\n0.5",
  "Below Tc\n0.5", "Pr[Female]\n0.5",
  "Above Tc\n0.5", "Pr[Male]\n0.2",
  "Above Tc\n0.5", "Pr[Female]\n0.8",
  "Pr[Male]\n0.5", "Male\n0.5 * 0.5 = 0.25",
  "Pr[Female]\n0.5", "Female\n0.5 * 0.5 = 0.25",
  "Pr[Male]\n0.2", "Male\n0.5 * 0.2 = 0.1",
  "Pr[Female]\n0.8", "Female\n0.5 * 0.8 = 0.4"
)

ggflowchart(FC2,
            horizontal = TRUE,
            arrow_size = 0.25,
            text_size = 4,
            x_nudge = 0.25)

```


## Solving with natural numbers

```{r}
#| fig-align: center

FC3 <- tribble(
  ~ from, ~ to,
  "Temperature\n100", "Above Tc\n0.5 * 100 = 50",
  "Temperature\n100", "Below Tc\n0.5 * 100 = 50",
  "Below Tc\n0.5 * 100 = 50", "Pr[Male]\n0.5 * 50 = 25",
  "Below Tc\n0.5 * 100 = 50", "Pr[Female]\n0.5 * 50 = 25",
  "Above Tc\n0.5 * 100 = 50", "Pr[Male]\n0.2 * 50 = 10",
  "Above Tc\n0.5 * 100 = 50", "Pr[Female]\n0.8 * 50 = 40",
  "Pr[Male]\n0.5 * 50 = 25", "Male\n25",
  "Pr[Female]\n0.5 * 50 = 25", "Female\n25",
  "Pr[Male]\n0.2 * 50 = 10", "Male\n10",
  "Pr[Female]\n0.8 * 50 = 40", "Female\n40"
)

ggflowchart(FC3,
            horizontal = TRUE,
            arrow_size = 0.25,
            text_size = 4,
            x_nudge = 0.25)
```

$$\frac{40}{40 + 25} = \frac{40}{65} = 0.62$$


















## old slides


## Tibbles, matrices, and data.frames

> Dataframes, matrices, and tibbles are still a bit confusing. Could you go over the differences in each one and how they are similar and different?

> When is it appropriate to select creating a tibble over a data frame?

> What is the best way to determine if there are formatting issues in the data.

- `str()`, `glimpse()`, `unique()`, `count()`


## Slicing

> I still don't understand slice_sample() very well or how it works. Could you please go over it?

NYC Air quality May-September 1973

```{r}
str(airquality)
```


## Slicing specific rows

```{r}
airquality[c(1, 3, 5), ]
airquality |> slice(1, 3, 5)
```


## 7 rows

```{r}
airquality[sample(1:nrow(airquality), 7), ]

airquality |> slice_sample(n = 7)
```


## 5% of rows

```{r}
airquality[sample(1:nrow(airquality), nrow(airquality) %/% 20), ]

airquality |> slice_sample(prop = 0.05)
```






## Probability

> One more slow explanation of conditional probability can't hurt. I think I just about understand it, but I want to really try and follow along.

> Could you go over an example similar to the cancer example in Problem Set 4? I am still struggling with interpreting Bayes' Rule. I understand how to set them up, but I am still working on interpreting what the question is asking!

> Can we briefly go over the prostate cancer example from Problem Set 4 - specifically how to solve it efficiently using R?

> I would like to go over the probability formula we used in unit 4. I feel like I still struggle with where to put each variable.

> I wouldn't mind another example of Bayes' Rule. I understand the premise but would like more practice with it.


## Probability

> How do you correctly identify true positives, false positives, true negatives, and false negatives based on the wording provided? Additionally, how does this relate to sensitivity and specificity?


## Probability

<center>
<img src="https://i.imgur.com/TdyYkUY.jpg" width="60%" />
</center>

- Sensitivity = [a/(a+c)] × 100 = True Positive *Proportion*
- Specificity = [d/(b+d)] × 100 = True Negative *Proportion*
- Positive predictive value(PPV) = [a/(a+b)] × 100
- Negative predictive value(NPV) = [d/(c+d)] × 100.

From: https://doi.org/10.3389/fpubh.2017.00307


