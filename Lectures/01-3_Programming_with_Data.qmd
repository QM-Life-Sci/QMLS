---
title: "Programming with Data"
author:
  - Elizabeth King
  - Kevin Middleton
format:
  revealjs:
    theme: [default, custom.scss]
    standalone: true
    self-contained: true
    logo: QMLS_Logo.png
    slide-number: true
    show-slide-number: all
code-annotations: hover
bibliography: QMLS_Bibliography.bib
csl: evolution.csl
---

```{r}
#| label: setup
#| echo: false

library(tidyverse)
```

---

> "For example, last month I was working on a problem of logistic regression that I suspected had mislabeled outcomes (some zeroes turned to ones, and vice versa), and read up on some robust logistic regression methods, implemented in the robust package. But I wasn't sure they would be effective on my data, so I did some random simulation of mislabeled outcomes and applied the method. The method didn't work as well as I needed it to, which saved me from applying it to my data and thinking I'd solved the problem.

---

> For this reason, no matter how much math and proofs there are that show a method is [reliable], I really only feel comfortable with a method once I've worked with it simulated data. It's also a great way to teach myself about the statistical method." [David Robinson](http://varianceexplained.org/r/simulation-bayes-baseball/)


## Learning a programming language

Like learning a foreign language.

- Practice
- Struggle
- Gradual proficiency
- Lectures, talks, and bootcamps won't help you as much as hands-on practice.


## What do you mean "programming"? {.smaller}

Modern Scientist == Programmer

- 95% of your analysis time is spent _not_ doing statistics.
    - Wrangling data
    - Plotting data
- Invest time now in learning the logic of programming. Save time later.
- Reproducibility. You always know what you did.
    - Code with comments reads as a step-by-step of your analysis
- This is a process.
    - It takes time to become comfortable.


## Why program?

> "If you had done something twice, you are likely to do it again." -- Brian Kernighan and Rob Pike


## Good things about programming with data

- Forces you to be explicit.
    - R won't give unless you ask.
- Forces you to have a record of your analysis.
    - Add to/modify your data and rerun
    - No point and click confusion
- Allows you to keep versions of your analysis
    - Revert to an older version


## R and RStudio

You are living in a good time.

- The R Renaissance (2012-present)
- The Dark Ages (1993-2011)

![](http://s3.crackedcdn.com/phpimages/article/0/2/5/208025_v1.jpg)


## The tidyverse

A set of packages to load, clean, filter, plot, and generally deal with data in a "tidy" way. Largely the work of [Hadley Wickham](http://hadley.nz/) and colleagues at Posit (RStudio).

```{r}
#| eval: false
#| echo: true

install.packages("tidyverse") # Once
library(tidyverse)
```

- Tidyverse Resources 
  - The Tidy Tools Manifesto
  - Guides & Tutorials 


## Writing clean code

Code should be understandable by others (and your future self)

- clean
- readable
- well annotated.


## Whitespace is your friend {.smaller}

- Separate elements and processes with spaces and line breaks
- Limit line length
- Use indenting to group code

Hard to read:

```{r}
#| eval: false
#| echo: true



tvtest<-lmer(sqrt(tv)~Region*log(DD5_TOT)+(1|Population/Sample_ID)+
(1|Year),data=tvdat,REML=FALSE)
summary(tvtest)
ggplot(tvdat,aes(x=log(DD5_TOT),y=sqrt(tv),col=Region))+
geom_point(shape=1,size=3,alpha=1/3)+ geom_smooth(aes(col=Region),method='lm')+
xlab(bquote('log(Degree Days above' ~5^o~C*')'))+ylab('sqrt(Terminal Velocity (m/s))')
```


## Whitespace is your friend {.smaller}

- Separate elements and processes with spaces and line breaks
- Limit line length
- Use indenting to group code

Easier to read:

```{r}
#| echo: true
#| eval: false

tvtest <- lmer(sqrt(tv) ~ Region * log(DD5_TOT) +
                 (1|Population/Sample_ID) + 
                 (1|Year), data = tvdat, 
               REML = FALSE)

summary(tvtest)

ggplot(tvdat, aes(x = log(DD5_TOT), y = sqrt(tv), col = Region)) +
  geom_point(shape = 1, size = 3, alpha = 1/3) +
  geom_smooth(aes(col = Region), method = 'lm') + 
  xlab(bquote('log(Degree Days above' ~5^o~C*')')) +
  ylab('sqrt(Terminal Velocity (m/s))')
```


## Annotations are messages to your future self (and others) {.smaller}

- Explain the reason & functionality of the code (important when you are a beginner!)
- Any useful messages

```{r}
#| echo: true
#| eval: false

# Linear mixed model
# Random effects: Sample nested in Population and Year
tvtest <- lmer(sqrt(tv) ~ Region * log(DD5_TOT) +
                 (1|Population/Sample_ID) + 
                 (1|Year), data = tvdat, 
               REML = FALSE)

# Summary output of the model
summary(tvtest)

# Plot tv vs. dd5_tot colored by Region
# alpha = transparency, smaller is more transparent
ggplot(tvdat, aes(x = log(DD5_TOT), y = sqrt(tv), col = Region)) +
  geom_point(shape = 1, size = 3, alpha = 1/3) +
  geom_smooth(aes(col = Region), method = 'lm') + 
  xlab(bquote('log(Degree Days above' ~5^o~C*')')) +
  ylab('sqrt(Terminal Velocity (m/s))')
```

## Assigning objects

Use `<-` for assign.

- Don't use `=` (even though you can).
- "Assign the object on the right to the object on the left."


## Kinds of data in R

- Character ("a", "Female", "The quick brown fox")
- Numeric (1.25, 1e6) or integer (1)
- Logical (`TRUE` or `FALSE`)
- Factor (categorical)


## Common R objects

1. Vectors
1. Matrices
1. `data.frame`s and `tibble`s
1. Functions


## Vectors

```{r}
#| echo: true

x <- c(112, 2.2, 7, 14.1)
x
x[2]
sort(x)
```


## Vectors

```{r}
#| echo: true

y1 <- 1:10
y2 <- seq(1, 10, length = 20)
y1[1:3]
y2[1:3]
```


## Vectors

```{r}
#| echo: true

x + 10
y1^2
min(x)
max(x)
```


## Vectors

```{r}
#| echo: true

sqrt(y2)
y2_mean <- mean(y2)
y2_sd <- sd(y2)
y2_mean
y2_sd
```


## Matrices

Rectangular object of *one data type*

- Indexed by [Rows, Columns] (think "RC Cola")
- Default is to fill by column (`byrow = TRUE` for row-wise)

```{r}
#| echo: true

M <- matrix(1:9, nrow = 3, ncol = 3)
M
M[2, 2]
```


## Matrices

```{r}
#| echo: true

M[1, ]
M[, 1]
```

![](https://i.imgur.com/1yKQBJZ.png){fig-align="center"}


## `data.frame()`: a basic unit of storage

Mixed data types per column

  - Numeric
  - Character
  - Factor (categorical)
  - Logical (`TRUE` and `FALSE`)


## Making data.frames

```{r}
#| echo: true

MM <- data.frame(x = 1:3,
                 y = c(10, 17, 21),
                 A = c("a", "b", "c"))
MM
```


## Extracting from data.frames

Either `$` or `[, ]` notation (with quoted column names).

```{r}
#| echo: true

MM$x
MM$A
MM[, "y"]
```


## Extracting from data.frames

```{r}
#| echo: true

MM[2, ]
MM[, 2]
```


## Tibbles 

Tibbles and `data.frame`s are essentially identical, but a `tibble` is more modern and works better with the data structure of the tidyverse. See `vignette("tibble")`.
    
- You can coerce a `data.frame` into a `tibble` with `as_tibble()`
- Tibbles never change the type of an input, never change the name of a variable, and never create row names.
- Tibbles only print 10 rows, and columns display their type (e.g., "chr", "int")


## Creating tibbles

```{r}
#| echo: true

MM <- tibble(x = 1:3,
             y = x ^ 2, # <1>
             A = c("a", "b", "c"))
MM
```

1. Creation of a column can refer back to previously created columns


## Creating tibbles with `tribble()`

- Row-wise creation
- Useful for small tibbles

```{r}
#| echo: true
tribble(
  ~x, ~y, ~A, # <1>
  1, 10, "a", # <2>
  2, 11, "b",
  3, 12, "c"
)
```

1. Supply column names with `~`
2. Each row is passed in sequence by column


## Functions

We will get to writing our own functions later, for now: `functionName()`, where parameters go inside `()`.

```{r}
#| echo: true

c(1)
sqrt(256)
```


## Functions

```{r}
#| echo: true

log(2.718)
exp(1)
```

Get help from the R command line with ?: `?sqrt` or `?log10`. Also try `help.search("mean")`, etc.


## Analysis workflow {.smaller}

1. Enter data (e.g., Excel)
1. Load raw data and perform manipulations
    * Recode variables
    * Create categorical variables where applicable
    * Combine and transform variables if necessary
1. Plot the raw data to look for mistakes, extreme values, etc.
    * Go back and fix errors
    * Explore your data
1. Statistical analysis
1. Interpretation
    * More analysis
1. Make tables and figures for publication


## Analysis workflow

![](https://i.imgur.com/fDpfRDA.png){fig-align="center"}
