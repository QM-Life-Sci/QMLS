---
title: "Making Decisions"
subtitle: "Uncertainty, Effect Sizes, & Hypothesis Testing"
author:
  - Elizabeth King
  - Kevin Middleton
format:
  revealjs:
    theme: [default, custom.scss]
    standalone: true
    self-contained: true
    logo: QMLS_Logo.png
    slide-number: true
    show-slide-number: all
code-annotations: hover
bibliography: QMLS_Bibliography.bib
csl: evolution.csl
---

```{r}
#| label: setup
#| echo: false

library(tidyverse)
library(cowplot)
theme_set(theme_cowplot())
#source("https://raw.githubusercontent.com/kmiddleton/quant_methods/master/Lectures/Shade_Distributions.R")
source("../../quant_methods/Lectures/Shade_Distributions.R")
library(patchwork)
library(magick)
library(ggpubr)

options(pillar.sigfig = 4)

```

## Goals of statistical inference

```{r}
set.seed(3575575)

Alive <- rnorm(n = 150, mean = 24.5, sd = 2.6)
Dead <- rnorm(n = 30, mean = 22.0, sd = 2.7)
Group <- c(rep("Alive", 150),
           rep("Dead", 30))

HL <- tibble(Horn_Length = c(Alive, Dead),
             Group = factor(Group))

liz <- image_read("https://tpwd.texas.gov/huntwild/wild/images/reptiles/horned_lizardlarge.jpg")

img <- ggplot() + background_image(liz) 


P_HL <- HL |>
  ggplot(aes(Group, Horn_Length)) +
  geom_point(position = position_jitter(width = 0.2, seed = 423479),
             alpha = 0.5, size = 3) 
P_HL +
  inset_element(img, left = 0.8, bottom = 0.7, right = 1, top = 1)

```

## What is the effect of group on horn length? 

```{r}
mu.a <- mean(HL$Horn_Length[HL$Group == "Alive"])
mu.d <- mean(HL$Horn_Length[HL$Group == "Dead"])

P_HL + 
  geom_segment(x = 0.6, y = mu.a, xend = 1.4, yend = mu.a, color = "steelblue", linewidth = 2) +
  geom_segment(x = 1.6, y = mu.d, xend = 2.4, yend = mu.d, color = "steelblue", linewidth = 2) +
  theme(text = element_text(size = 20))
 

```

## What is the effect of group on horn length? 

```{r}
P_HL + 
  geom_segment(x = 0.6, y = mu.a, xend = 1.4, yend = mu.a, color = "steelblue", linewidth = 2) +
  geom_segment(x = 1.6, y = mu.d, xend = 2.4, yend = mu.d, color = "steelblue", linewidth = 2) +
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = 0.1,
               color = "red", linewidth = 2) + 
  theme(text = element_text(size = 20))

```

## What is the effect of group on horn length? 

```{r}
dd <- mu.a - mu.d
P_HL + 
  geom_segment(x = 0, y = mu.a, xend = 3, yend = mu.a, color = "steelblue", linewidth = 2) +
  geom_segment(x = 0, y = mu.d, xend = 3, yend = mu.d, color = "steelblue", linewidth = 2) +
  theme(text = element_text(size = 20)) +
  annotate("text", x = 1.5, y = mu.d + 0.5*dd, label = paste0("Effect Size = ", round(dd, 2)))

```

## How certain are we of the effect of group?

```{r}
ttt <- t.test(Horn_Length ~ Group, data = HL)
g_mu <- mean(c(mu.a, mu.d))
ll <- ttt$conf.int[1]
uu <- ttt$conf.int[2]

HL |>
  ggplot(aes(Group, Horn_Length)) +
  geom_rect(xmin = 0, xmax = 2.2, ymin = g_mu - 0.5*uu, ymax = g_mu + 0.5*uu, fill = "lightblue") +
  geom_rect(xmin = 0, xmax = 2.2, ymin = mu.d, ymax = mu.a, fill = "steelblue") +
  geom_rect(xmin = 0, xmax = 2.2, ymin = g_mu - 0.5*ll, ymax = g_mu + 0.5*ll, fill = "navy") +
  geom_segment(y = g_mu - 0.5*ll, yend = g_mu + 0.5*ll, x = 2.23, xend = 2.23, color = "navy", linewidth = 2) +
  annotate("text", x = 2.33, y = mu.d + 0.5*dd, label = paste0("Lower \n", round(ll, 2))) +
  geom_segment(y = mu.d, yend = mu.a, x = 2.43, xend = 2.43, color = "steelblue", linewidth = 2) +
  annotate("text", x = 2.53, y = mu.d + 0.5*dd, label = paste0("Effect\nSize\n", round(dd, 2))) +
  geom_segment(y = g_mu - 0.5*uu, yend = g_mu + 0.5*uu, x = 2.63, xend = 2.63, color = "lightblue", linewidth = 2) +
  annotate("text", x = 2.73, y = mu.d + 0.5*dd, label = paste0("Upper \n", round(uu, 2))) +
  geom_point(position = position_jitter(width = 0.2, seed = 423479),
             alpha = 1/2, size = 3) +
  expand_limits(x=c(0,3)) +
  theme(text = element_text(size = 20)) 

```

## Standardized effect size

## How does the mean change in alive lizards compared to dead? 


Horn length in live horned lizards: `r round(mean(HL$Horn_Length[HL$Group == "Alive"]), 1)` mm

Horn length in dead horned lizards: `r round(mean(HL$Horn_Length[HL$Group == "Dead"]), 1)` mm

Imagine you collected 180 live horned lizards and randomly assigned 150 to one group and 30 to the other.

- Do you think they would have the same mean horn length?
- How different do you think the means would be?
- Think about how the variability among individual horn length measurements would affect your intuition here.



## How large of a difference do we expect from sampling error?

:::: {.columns}

::: {.column width="50%"}
![](https://i.imgur.com/EIfjPa0.jpg){fig-align="center" width=100%}
:::

::: {.column width="50%"}
- Imagine a distribution of horn lengths for a population of horned lizards (mean = 24, sd = 2.6)
- Randomly catch two groups of $n = 150$ and  $n = 30$ from this population
- How different are the groups?
:::

::::


## How large of a difference do we expect from sampling error?

```{r}
#| echo: true
#| eval: false

set.seed(883231)

mu.horn <- 24   # mean
sd.horn <- 2.6    # standard deviation
n.iter <- 100000 # number of iterations
n.samp1 <- 150    # number in first sample
n.samp2 <- 30    # number in second sample
sim.diff <- tibble(dd = numeric(length = n.iter)) # to hold output  

for (zz in 1:n.iter) {
  s1 <- rnorm(n.samp1, mu.horn, sd.horn) # sample 1
  s2 <- rnorm(n.samp2, mu.horn, sd.horn) # sample 2
  sim.diff[zz, 'dd'] <- mean(s1) - mean(s2) # difference in means
}
```

## dotplot
dotplot

## How large of a difference do we expect from sampling error?


```{r}

sim.diff <- readRDS("../data/Random_horns.rds")

ggplot(sim.diff, aes(x = dd)) +
  geom_histogram(bins = 30, fill = "gray50") +
  labs(x = "Difference of Means", y = "Count")
```

## How large of a difference do we expect from sampling error?

```{r}
p1 <- ggplot(sim.diff, aes(x = dd)) +
  geom_histogram(bins = 30, fill = "gray50") +
  labs(x = "Difference of Means", y = "Count")

HL_mean <- HL |> 
  group_by(Group) |> 
  summarize(Mean = mean(Horn_Length)) |> 
  gather(Value, x, -Group)

p2 <- HL |> 
  ggplot(aes(Horn_Length)) +
  geom_histogram(bins = 30, fill = "gray50") +
  geom_vline(data = HL_mean, aes(xintercept = x, color = Value),
             linewidth = 2, color = "firebrick4") +
  facet_grid(Group ~ .) +
  labs(x = "Horn Length (mm)", y = "Count") +
  theme(legend.position = "none")

plot_grid(p2, p1, ncol = 2)
```

<center>
Observed difference = `r round(mean(HL$Horn_Length[HL$Group == "Alive"]), 1) - round(mean(HL$Horn_Length[HL$Group == "Dead"]), 1)` mm
</center>




## Goals of Statistical Inference

1. Parameter (i.e. effect) estimation
    - Given a model, with unknown parameters ($\theta_0$, $\theta_1$, ..., $\theta_k$), how to estimate values of those parameters?
2. Interval estimation
    - How to quantify the uncertainty associated with parameter estimates?
3. Making decisions (i.e. Hypothesis testing)
    - How to test hypotheses about parameter estimates?
    - What conclusions can we make from our analysis?
    
## Hypotheses

**Hypothesis**: a statement that can be either true or false

**Statistical hypothesis**: a hypothesis about about a parameter (or parameters) of a population or process

- Many statistical analyses have the goal of performing a hypothesis test.


## How large of a difference do we expect from sampling error?

```{r}
p1 <- ggplot(sim.diff, aes(x = dd)) +
  geom_histogram(bins = 30, fill = "gray50") +
  labs(x = "Difference of Means", y = "Count")

HL_mean <- HL |> 
  group_by(Group) |> 
  summarize(Mean = mean(Horn_Length)) |> 
  gather(Value, x, -Group)

p2 <- HL |> 
  ggplot(aes(Horn_Length)) +
  geom_histogram(bins = 30, fill = "gray50") +
  geom_vline(data = HL_mean, aes(xintercept = x, color = Value),
             linewidth = 2, color = "firebrick4") +
  facet_grid(Group ~ .) +
  labs(x = "Horn Length (mm)", y = "Count") +
  theme(legend.position = "none")

plot_grid(p2, p1, ncol = 2)
```

<center>
Observed difference = `r round(mean(HL$Horn_Length[HL$Group == "Alive"]), 1) - round(mean(HL$Horn_Length[HL$Group == "Dead"]), 1)` mm
</center>

## Making Decisions {.smaller}

>What is the probability of observing a difference as big or bigger than my observed difference from sampling error alone? 

The answer to this question is called a p-value: p = 4/100000 = 0.00004


```{r}
set_above <- sim.diff[sim.diff$dd >= dd | sim.diff$dd <= -dd,]
set_above$y = 1
p1 <- ggplot(sim.diff, aes(x = dd)) +
  geom_histogram(bins = 30, fill = "gray50") +
  geom_vline(xintercept = c(-dd,dd), linewidth = 2, color = "firebrick4") +
  geom_point(data = set_above, aes(dd, y), size = 3, alpha = 0.8, color = "firebrick4") +
  labs(x = "Difference of Means", y = "Count") 
p1

```


## Obtaining P-values

Fix shade 

- Calculate test statistic
- Determine *P*-value (area under tail(s))

:::: {.columns}

::: {.column width="50%"}

```{r, echo=FALSE, fig.height=3.7,fig.width=3.5}
shade_t(0.025, 178,tail = "both")
```

:::

::: {.column width="50%"}


```{r, echo=FALSE, fig.height=3.7,fig.width=3.5}
shade_t(0.05, 178,tail = "upper")
```

:::

::::

## Obtaining P-values {.smaller}

```{r}
#| echo: true

summary(lm(Horn_Length ~ Group, data = HL))

```


## One sided or two-sided tests {.smaller}

Data will always be on one side of H~0~ or the other.

**One-sided test** ("one-tailed"):

- Appropriate when we have an *a priori* hypothesis of the direction of change

- You need justification and to be explicit about it, when you report a one-sided test.

**Two-sided test** ("two-tailed"):

- *Appropriate at all other times.*
- Multiply the one-sided *P* by 2.


## Closed-form P-value

- Calculate test statistic
- Determine *P*-value (area under tail(s))

:::: {.columns}

::: {.column width="50%"}

```{r}
shade_t(0.15, 10,tail = "both") +
  ggtitle("P = 0.3")
```

:::

::: {.column width="50%"}

```{r}
shade_t(0.005, 10,tail = "both") +
    ggtitle("P = 0.01")

```

:::

::::


## Testing different hypotheses {.smaller}

$$t = \frac{\theta - \theta_{null}}{\mbox{SE}_{\theta}}$$

is a general equation that can be used to test any null hypothesized parameter estimate.

- $\theta$ is the parameter estimate
- $\theta_{null}$ is the null hypothesized value
    - often and by default $\theta_{null} = 0$
- Analyses of allometry: the study of scaling relationships

## Bayesian Inference

- Does the Credible Interval of a given parameter estimate encompass the value in question. e.g.,:
    -  Does the credible interval for the difference in means include zero?
    -  Does the credible interval for the parameter estimate include 98.6?

## Decision errors {.smaller}

|               | Reject H~0~    | Fail to reject H~0~   |
|--------------:|:--------------:|:---------------------:|
|H~0~ is true   | Type I error   | *Correct*             |
|H~0~ is false  | *Correct*      | Type II error         |

Type I error occurs when:

- You decide there is an important effect when in reality there isn't one.

Type II error occurs when:

- You decide there is not an important effect when in reality there is one.

## Power

- Probability that a random sample will lead to a rejection of H~0~
- Dependent on how different the truth is from the null hypothesis
- Inversely related to type II errors
    - High power $\rightarrow$ low type II errors
    - Low power $\rightarrow$ high type II errors
- Power analysis will come later in the course

## Making Decisions

```{r}

g1 <- tibble("group" = rep("g1", 3),
             "y" = rep(1,3),
             "x" = c(0.01,0.31,0.61),
             "Effect" = rep(0.31,3),
             "P" = rep(0.05, 3),
             "Significant" = rep("*", 3)
             )

g2 <- tibble("group" = rep("g2", 3),
             "y" = rep(2,3),
             "x" = c(0.08,0.1,0.12),
             "Effect" = rep(0.1,3),
             "P" = rep(0.008, 3),
             "Significant" = rep("*", 3)
             )

g3 <- tibble("group" = rep("g3", 3),
             "y" = rep(3,3),
             "x" = c(0.64,0.72,0.8),
             "Effect" = rep(0.72,3),
             "P" = rep(0.0001, 3),
             "Significant" = rep("*", 3)
             )

g4 <- tibble("group" = rep("g4", 3),
             "y" = rep(4,3),
             "x" = c(0,0.31,0.62),
             "Effect" = rep(0.31,3),
             "P" = rep(0.06, 3),
             "Significant" = rep("ns", 3)
             )

g5 <- tibble("group" = rep("g5", 3),
             "y" = rep(5,3),
             "x" = c(-0.18,0.09,0.36),
             "Effect" = rep(0.09,3),
             "P" = rep(0.7, 3),
             "Significant" = rep("ns", 3)
             )

g6 <- tibble("group" = rep("g6", 3),
             "y" = rep(6,3),
             "x" = c(0.32,0.47,0.62),
             "Effect" = rep(0.47,3),
             "P" = rep(0.005, 3),
             "Significant" = rep("*", 3)
             )

g7 <- tibble("group" = rep("g7", 3),
             "y" = rep(7,3),
             "x" = c(0.04,0.44,0.84),
             "Effect" = rep(0.4,3),
             "P" = rep(0.02, 3),
             "Significant" = rep("*", 3)
             )
g8 <- tibble("group" = rep("g8", 3),
             "y" = rep(8,3),
             "x" = c(0.1,0.18,0.26),
             "Effect" = rep(0.18,3),
             "P" = rep(0.01, 3),
             "Significant" = rep("*", 3)
             )

g9 <- tibble("group" = rep("g9", 3),
             "y" = rep(9,3),
             "x" = c(-0.05,0.44,0.93),
             "Effect" = rep(0.44,3),
             "P" = rep(0.2, 3),
             "Significant" = rep("ns", 3)
             )

gall <- rbind(g1, g2,g3,g4,g5,g6,g7,g8,g9)

bks <- -log10(c(0.001,0.01,0.05,0.2,0.5))
lbs <- c(0.001,0.01,0.05,0.2,0.5)

dec.plot <- ggplot(gall, aes(x,y, group = group, color = -log10(P))) +
  geom_rect(xmin = -0.4, xmax = 0.2, ymin = 0, ymax = 12, fill = "lightgoldenrod", color = "lightgoldenrod") +
  geom_rect(xmin = 0.2, xmax = 0.5, ymin = 0, ymax = 12, fill = "grey", color = "grey") +
  geom_rect(xmin = 0.5, xmax = 1.5, ymin = 0, ymax = 12, fill = "thistle", color = "thistle") +
  geom_vline(xintercept = 0, linetype = "dotted", color = "grey30") +
  geom_line(linewidth = 3) +
  geom_point(data=gall, aes(Effect,y,color = -log10(P)), size = 5) +
  xlim(c(-0.2, 1)) +
  ylab("Experiment") +
  xlab("Standardized Effect Size") +
  scale_color_gradient(breaks = bks, labels = lbs, low = "black", high = "red", name = "P-value") +
  annotate("text", x = 0, y = 10.5, label = "Not Biologicaly\nMeaningful") +
  annotate("text", x = 0.35, y = 10.5, label = "Uncertain") +
  annotate("text", x = 0.75, y = 10.5, label = "Clearly Biologicaly\nMeaningful") +
  ylim(c(1,11)) +
  theme(axis.text.y = element_blank(), text = element_text(size = 20))

dec.plot
```

Figure inspired by Ian Dworkin

## Problems with All or Nothing Thinking

Null hypothesis significance testing is often used inappropriately as an all or nothing decision-making tool.

```{r}

nhst.plot <- ggplot(gall, aes(x,y, group = group, color = Significant)) +
  geom_line(linewidth = 3) +
  geom_point(data=gall, aes(Effect,y,color = Significant), size = 5) +
  geom_vline(xintercept = 0, linetype = "dotted", color = "grey30") +
  scale_color_manual(values = c("red","black"))+
  ylab("Experiment") +
  xlab("Standardized Effect Size") +
  theme(axis.text.y = element_blank())  +
    theme(axis.text.y = element_blank(), text = element_text(size = 20))

nhst.plot


```



## Controversy

Philosophical and practical problems have been raised since the 1960's.

- In 1986, the *American Journal of Public Health* told all researchers wanting to publish in the journal that he would no longer accept results based on *P*-values (and then backed down 2 years later)
- *Basic and Applied Social Psychology* banned *P*-values in 2015
- In 2016, the American Statistical Association published a "Statement on *P*-Values: Context, Process, and Purpose" which critiqued the (mis)use of *P*-values.

## History

- K. Pearson: Pearson's correlation, $\chi^2$, eugenics
- Fisher: Fisher's exact test, "null hypothesis", ANOVA (*F*), eugenics
- Gosset: *t* distribution, Student's *t*-tests, Guinness
- Neyman and E. Pearson: "null hypothesis" testing, confidence intervals, decision theory

## History

The modern idea is traced to these statisticians, but has been warped into something different:

- Test statistics ($F$, $t$, $\chi^2$) and Fisher's rule-of-thumb $P = 0.05$ applied to Neyman-Pearson "null hypotheses"
- H~0~ becomes a straw man hypothesis of no difference or no effect

## Problem with *P*-values

- Originally an informal concept that got co-opted for what became null hypothesis significance testing (NHST)
- Apparent objectivity but actually arbitrary and dependent on the data collected and not collected
- Experimental biases (experimenter introduced, sample size)
- Science-wide publication bias

## Science-wide publication bias {.smaller}

Corollaries proposed by Ioannidis [-@Ioannidis2005-od]:

1. The smaller the studies conducted in a scientific field, the less likely the research findings are to be true.
2. The smaller the effect sizes in a scientific field, the less likely the research findings are to be true.
3. The greater the number and the lesser the selection of tested relationships in a scientific field, the less likely the research findings are to be true.
4. The greater the flexibility in designs, definitions, outcomes, and analytical modes in a scientific field, the less likely the research findings are to be true.
5. The greater the financial and other interests and prejudices in a scientific field, the less likely the research findings are to be true.
6. The hotter a scientific field (with more scientific teams involved), the less likely the research findings are to be true.

## How to make decisions
incrmentl

- Always consider the size of the effect on a biological scale and incorporate this into your decision about how meaningful the effect is.
    - Significance alone may not mean a biological effect is important.
- Always consider your level uncertainty in your decision and report this clearly and openly.
    - No decision is made with 100% certainty. Embrace uncertainty and discuss the grey areas.

## How to make decisions

:::: {.columns}

::: {.column width="50%"}


```{r, fig.height=10}

dec.plot

```

:::

::: {.column width="50%"}


```{r, fig.height=10}

nhst.plot

```

:::

::::



## Alternative suggested approaches

Preregistration of experimental design and planned analysis

1. Report parameter estimates and confidence intervals only 
1. Model selection

Either of above could be done in a frequentist/likelihood or Bayesian framework


## References

::: {#refs}
:::
