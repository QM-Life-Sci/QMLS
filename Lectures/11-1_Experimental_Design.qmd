---
title: "Experimental Design"
subtitle: "Introduction"
author:
  - Elizabeth King
  - Kevin Middleton
format:
  revealjs:
    theme: [default, custom.scss]
    standalone: true
    self-contained: true
    logo: QMLS_Logo.png
    slide-number: true
    show-slide-number: all
code-annotations: hover
bibliography: QMLS_Bibliography.bib
csl: evolution.csl
---

## Why you should care about experimental design


```{r}
#| label: setup
#| echo: false

library(tidyverse)
library(cowplot)
library(GGally)
library(readxl)
theme_set(theme_cowplot())

```

1. Ethics
1. Time
1. Money

## Experimental Design Issues for Data Analysis

- Challenges and limits of what we can learn from life sciences data
- Repeatability
    - How much error do we expect in our measurements?
- Designing experiments to minimize decision errors/mistakes
    - Mistake 1: Predictor(s) is important when it really isn't
    - Mistake 2: Predictor(s) is not important when it really is

## Do these first: 

- Define (and write down) your main question
    - What do I want to learn?
- Define useful models

Key questions to ask at every step:

1. **What question am I trying to answer?**
1. **What processes could have produced the pattern I am observing?**

## Planning

- What data will I collect?
- How will I analyze the data?
    - What questions can and cannot be answered by my dataset? Consider all the possibilities.

What other data can I collect at the same time that might be useful at some unknown time in the future?

## Critical issues in the life sciences

1. Random variation
    - Why do we need replication?
1. Confounding factors
    - Complexity and interdependence is a feature of most life sciences systems

## Random variation (a.k.a. sampling error)

**What processes could have produced the pattern I am observing?**

![](../images/fish_sample.jpg){fig-align="center" width="100%"}
- Replication allows you to partition random variation and variation attributable to a predictor of interest

## Replication & Pseudoreplication

**Replication is needed to estimate variation within a group.**

- Replicates must be independent

Think about:

- Common field environments, shared enclosures
- Observations made in batches (days, months, years)
- Repeated measures of a single individual
- Measurements of genetically related units or related species

Many issues can be addressed statistically if you use an appropriate model.

## What level needs replication?

**What question am I trying to answer?**

- You cannot infer causation if you have not do not have **independent** replicates of the potential causal factor.

## Replication & Pseudoreplication

- Leaf area at one high rainfall and one low rainfall site (10 plots per site)

<center>
<img src="https://i.imgur.com/IT3QIvi.png" width="55%" />
</center>


## Replication & Pseudoreplication

:::: {.columns}

::: {.column width="70%"}

```{r}
set.seed(6239)
LA <- tibble("LeafArea"= c(rnorm(10,4,1),rnorm(10,7,1)),
             "Rainfall" = rep(c("Low","High"),each=10))

ggplot(LA, aes(Rainfall, LeafArea)) +
  geom_point(position = position_jitter(width = 0.05), alpha = 0.5) +
  stat_summary(fun = mean, geom = "point", size = 3, color = "red") +
  stat_summary(fun.data = mean_se, geom = "errorbar", width = 0.1,
               color = "red", size = 0.7) +
  labs(x = "Rainfall", y = "Leaf Area")

```

:::

::: {.column width="30%"}

What else might differ between these two individual sites besides rainfall?

:::

::::

## Replication & Pseudoreplication

  - Any two groups are expected to differ for any number of reasons.
    - Replication within these groups will just reveal this difference, not show causality
  - You need replication at the level of your variable of interest 


## Random sampling and confounding factors

Independence is a critical assumption in (nearly) all your analyses

- Non-random sampling precludes independence

Can we really expect samples to be completely independent?

- Museum specimens
- Fossil record

**What processes could have produced the pattern I am observing?**

## Confounding factors

Marmots across altitudes & temperatures

```{r echo=FALSE}
set.seed(188)

tt <- signif(runif(30, 8, 28), digits = 3)
aa <- round(-500 * tt + rnorm(30, 17000, 500))

mm <- signif(-1.5 * tt + 0.001 * aa + 150 + rnorm(30, 0, 6))

MM <- data.frame("MarmotID" = paste0("M", seq(1, 30)),
                 "Altitude" = aa, 
                 "Temperature" = tt, 
                 "MetabolicRate" = mm)

ggscatmat(MM, columns = 2:4)

```

## Examples?


## Subjectivity in data analysis

> "None of this should be understood to mean that any statistical analysis is not inherently subjective, because of course it is--lots of little subjective decisions are involved in all parts of science. It's just that priors and Bayesian data analysis are no more inherently subjective than are likelihoods and the repeat sampling assumptions required for significance testing. Anyone who has visited a statistics help desk at a university has probably experienced this subjectivity--statisticians do not in general exactly agree on how to analyze anything but the simplest of problems." [@McElreath2015-no]
## References




::: {#refs}
:::
