---
title: "Unit 9: In Class Discussion"
author:
  - Elizabeth King
  - Kevin Middleton
format:
  revealjs:
    theme: [default, custom.scss]
    standalone: true
    self-contained: true
    logo: QMLS_Logo.png
    slide-number: true
    show-slide-number: all
code-annotations: hover
bibliography: QMLS_Bibliography.bib
csl: evolution.csl
---

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
#| label: setup
#| message: false
#| warning: false

library(tidyverse)
library(cowplot)
library(wesanderson)
library(lme4)

theme_set(theme_cowplot())
```

## Upcoming Events

- Course Evaluations
- Last Review Session
  - Change time?

## General questions

- PS 2: next week


## Quiz 9-1 {.smaller}

- Regarding the process of determining important estimates from the interaction plots, could you assist me in reaching these conclusions, are there any particular patterns or trends that I should be searching for in the graphs?"
- You discussed interaction plots and the "power to detect interactions" and showed the power to detect main effect and interaction. I'm a bit confused on the power to detect, the significance, and how to find it.
- You mentioned that the main effects are not interpretable without clarification of an ANOVA table and, further, that the power to detect interactions is relatively low.  How exactly does ANOVA help make this interpretable?


## Quiz 9-3

- There was a low R^2^ value which indicates low correlation, but a low P value which indicates a statistically significant model.  How is it that we can have a low P value and still not be confident in either variable as a good predictor of our estimated value?  How can the overall model be statistically significant if only a small percentage of variability can be explained by the variables input in the formula?


## R^2^, *P*-values, and effect size {.smaller}

*Arabidopsis* growth

We measured above ground biomass of plants after six weeks of growth in each of two treatment groups (n = 1000 per group). The means were 10.31 g (SEM = 0.001) for the control group and 10.42 (SEM = 0.002) for the fertilizer treatment group. A paired t-test showed highly significant difference of treatment ($t_{1998}$ = 52.4, P << 0.0001).

*Drosophila* larval density

You perform a multiple regression predicting wing area in *Drosophila melanogaster* using larval density and temperature. You have a very large data set (n = >1,000 observations). The R^2^ value for the regression is 0.02, and the overall *P*-value for the linear model is 0.0003.


## `anova()` vs. `Anova()`

- In lecture 9-3, you mentioned that there is `Anova` and `anova.` How are they different from one another, and in what cases would we want to use each one in?
- How do we determine which anova analysis we should use for a certain purpose?


## Balanced experimental design {.smaller}

- In the case of technical replicates, what should you do if one of the technical replicates is an outlier (either by experimenter error or equipment error)? Remove it and have unbalanced sample replicates? Or leave it in? I am struggling to figure out which would be the better route to go. (I come across this issue in my own research, which is why I am curious).
- I also had this question when looking at the cranial growth rates example during the lecture. I assume the answer for fixing it or leaving it would be situational, but I was also curious what is recommended when the outliers are heavily influencing the results of the model.


## Multilevel/Hierarchical/Mixed models

- In section 09-04, there are different options for multilevel models like `nlme`, `lme4`, `glmmTMB`. How do I decide which model is correct for my analysis?
- Lecture 09-04: What did you mean by "random" slopes and intercepts in the visualization example?
- How does the use of blocking and nesting in experimental design affect the validity and efficiency of statistical analyses, particularly in the context of complex experimental setups or hierarchical data structures?


## Multilevel/Hierarchical/Mixed models

- How does sample size impact interaction effect and multilevel models? Are there any corrective tests that can be used to address a small sample size and make a model fit better?
- I have seen models that will include the same variable as both a fixed and random effect. I'm wondering if/when this is appropriate.
- Could you explain the multilevel formula syntax 1 more time? I did not understand what to use in place of effect expression and groups. 


## Multilevel/Hierarchical/Mixed models

- In slides 17 & 18 of lecture 9-4, you say that the multilevel model formula is two functions separated by a "|". In slide 18 you set one of those functions equal to 1 and say it is to account for the random effect of the technical replicate, and then you say that it is referring to the intercept for the samples. So in this case, we are just forcing that intercept to 1, and that's how we take a rough average of the technical samples? Why don't we take a true average? What would be a scenario where that function would be `x` or `x+1`?


## Visualization of Hierarchical Modeling

[http://mfviz.com/hierarchical-models/](http://mfviz.com/hierarchical-models/)


## Data

```{r}
set.seed(543675)
departments <- c('sociology', 'biology', 'english', 'informatics', 'statistics')
base.salaries <- c(40000, 50000, 60000, 70000, 80000)
annual.raises <- c(2000, 500, 500, 1700, 500)
faculty.per.dept <- 20
total.faculty <- faculty.per.dept * length(departments)

# Generate dataframe of faculty and (random) years of experience
ids <- 1:total.faculty
department <- rep(departments, faculty.per.dept)
experience <- floor(runif(total.faculty, 0, 10))
bases <- rep(base.salaries, faculty.per.dept) * 
  runif(total.faculty, 0.9, 1.1) # noise
raises <- rep(annual.raises, faculty.per.dept) * 
  runif(total.faculty, 0.9, 1.1) # noise
df <- data.frame(ids, department, bases, experience, raises)

# Generate salaries (base + experience * raise)
df <- df |> mutate(
    salary = bases + experience * raises)

p <- ggplot(df, aes(x = experience, y = salary, color = department)) +
  geom_point(size = 3)
p
```


## `Salary ~ 1 + Exp`

- No difference in starting salary by department
- No difference in rate of change between departments

```{r}
#| fig-align: center

fm1 <- lm(salary ~ 1 + experience, data = df)

preds <- crossing(department = unique(df$department),
                    experience = c(0, 10))
preds <- preds |> 
  mutate(fm1 = predict(fm1, newdata = preds))

p +
  geom_line(data = preds, aes(x = experience, y = fm1), color = "firebrick4",
            linewidth = 1.5)
```


## `Salary ~ 1 + Exp + Dept`

- Different starting salary by department
- No difference in rate of change between departments


```{r}
#| fig-align: center

fm2 <- lm(salary ~ 1 + experience + department, data = df)

preds <- preds |> 
  mutate(fm2 = predict(fm2, newdata = preds))

p +
  geom_line(data = preds, aes(x = experience, y = fm2, color = department),
            linewidth = 1.5) +
  geom_line(data = preds, aes(x = experience, y = fm1), color = "firebrick4",
            linewidth = 1.5)
```


## `Salary ~ 1 + Exp + (1 | Dept)`

- Different starting salary by department *also using information from other departments*
- No difference in rate of change between departments

```{r}
fm3 <- lmer(salary ~ 1 + experience + (1 | department), data = df)

preds <- preds |> 
  mutate(fm3 = predict(fm3, newdata = preds))
```


## `Salary ~ 1 + Exp + (1 | Dept)`

```{r}
#| fig-align: center

p +
  geom_line(data = preds, aes(x = experience, y = fm3, color = department),
            linewidth = 2, linetype = "dotted") +
  geom_line(data = preds, aes(x = experience, y = fm2, color = department),
            linewidth = 1, alpha = 0.5) +
  geom_line(data = preds, aes(x = experience, y = fm1), color = "firebrick4",
            linewidth = 1.5)
```


## Predictions

```{r}
preds |> filter(department %in% c("sociology", "statistics")) |> knitr::kable()
```


## `Salary ~ 1 + Exp * Dept`

- Back to `lm()`
- Different starting salary by department
- Different rate of change between departments


## `Salary ~ 1 + Exp * Dept`

```{r}
#| fig-align: center

fm4 <- lm(salary ~ 1 + experience * department, data = df)

preds <- preds |> 
  mutate(fm4 = predict(fm4, newdata = preds))

p +
  geom_line(data = preds, aes(x = experience, y = fm4, color = department),
            linewidth = 1.5)
```


## `Salary ~ 1 + Exp + (1 + Exp | Dept)`

- Different starting salary by department *also using information from other departments*
- Different rate of change between departments *also using information from other departments*


## `Salary ~ 1 + Exp + (1 + Exp | Dept)`

```{r}
#| fig-align: center

fm5 <- lmer(salary ~ 1 + experience + (1 + experience | department), data = df)

preds <- preds |> 
  mutate(fm5 = predict(fm5, newdata = preds))

p +
  geom_line(data = preds, aes(x = experience, y = fm5, color = department),
            linewidth = 1, alpha = 0.5) +
  geom_line(data = preds, aes(x = experience, y = fm4, color = department),
            linewidth = 2, linetype = "dashed") +
  geom_line(data = preds, aes(x = experience, y = fm1), color = "firebrick4",
            linewidth = 1.5)
```


