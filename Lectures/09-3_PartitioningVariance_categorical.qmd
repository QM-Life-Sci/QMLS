---
title: "Partitioning Variance"
subtitle: "Categorical Variables"
author:
  - Elizabeth King
  - Kevin Middleton
format:
  revealjs:
    theme: [default, custom.scss]
    standalone: true
    self-contained: true
    logo: QMLS_Logo.png
    slide-number: true
    show-slide-number: all
code-annotations: hover
bibliography: QMLS_Bibliography.bib
csl: evolution.csl
---


## "Analysis of Variance"

```{r}
#| label: setup
#| echo: false
#| message: false
#| warning: false

library(tidyverse)
library(cowplot)
theme_set(theme_cowplot())

library(readxl)
library(car)
library(paletteer)
library(ggsci)
library(wesanderson)

```


<!--
Datasets
  biomass.csv
-->

Some total variability in $y$:

1. Part explained by group membership
1. Part remains unexplained: "error" or "residual"

$F$-statistic is the ratio of the two.


## Visualizing ANOVA

![](https://i.imgur.com/dNF4ph0.png){fig-align="center"}

$$F = \frac{\mbox{Between Group Variation}}{\mbox{Within Group Variation}}$$


## Parts of an ANOVA table

```{r}
#| echo: true
JL <- read_csv("../data/JetLag.csv", show_col_types = FALSE) |> 
  mutate(Treatment = factor(Treatment))
fm_lm <- lm(Shift ~ Treatment, data = JL)

anova(fm_lm)
```


## How much variation is explained by group membership: $R^{2}$?

```{r}
anova(fm_lm)
```

- `Sum Sq`: Variability accounted for by that part of the ANOVA
- `Mean Sq`: `Sum Sq` / `Df`
- `F value`: `Mean Sq` Treatment / `Mean Sq` Residual
- `Pr(>F)`: *P*-value for the *F*-test of that variable


## How much variation is explained by group membership: $R^{2}$?

$$R^{2} = \frac{\mbox{Variation accounted for by group membership}}{\mbox{Total variation}}$$
<br />

$$R^{2} = \frac{\mbox{Sum Sq Group}}{\mbox{(Sum Sq Group + Sum Sq Residuals)}}$$


## How much variation is explained by group membership: $R^{2}$?

```{r}
anova(fm_lm)
```

```{r}
#| echo: true
anova(fm_lm)$`Sum Sq`[1]/sum(anova(fm_lm)$`Sum Sq`)

7.224492/(7.224492 + 9.415345)
```


## How much variation is explained by group membership: $R^{2}$?

```{r}
summary(fm_lm)
```


## Unbalanced categorical datasets are complicated

ANOVA tables, sums of squares, and hypothesis tests are all impacted

- As soon as there is an unbalanced design, variables can share variance.
- When sample sizes are equal in all groups, the correlation between predictor variables is 0 and there is no shared variance. 

## Balanced Design

:::: {.columns}

::: {.column width="50%"}


```{r}
yy <- tibble(SoilType = c(1, 1, 1, 1, 1, 1,
                          0, 0, 0, 0, 0, 0),
             LightLevel = c(1, 1, 1, 0, 0, 0,
                            1, 1, 1, 0, 0, 0))
knitr::kable(head(yy))
```


:::

::: {.column width="50%"}

```{r, fig.width = 6}
#| message: false
#| warning: false

ggplot(yy, aes(LightLevel, SoilType)) +
  geom_jitter(width = 0.05, height = 0.05, alpha = 0.5, size = 4) +
  geom_smooth(formula = y ~ x, method = "lm", se = FALSE)
```

:::

::::

## Unbalanced Design

:::: {.columns}

::: {.column width="50%"}


```{r}

yy <- tibble(SoilType = c(0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,
                          0, 0, 0, 0, 0, 0, 0),
             LightLevel = c(0, 0, 0, 1, 1, 1, 1, 1, 1, 0,
                            0, 0, 1, 1, 1, 0, 0, 0, 0))
yy |> group_by(SoilType, LightLevel) |>
  tally()
```


:::

::: {.column width="50%"}

```{r, fig.width = 6}
#| message: false
#| warning: false

ggplot(yy, aes(LightLevel, SoilType)) +
  geom_jitter(width=0.05, height=0.05, alpha=0.5, size = 4) +
  geom_smooth(formula = y ~ x, method = "lm", se = FALSE)
```

:::

::::


## Partitioning variance

Different ways to partition variance has a cascading effect:

- Determines sums of squares, which
- Determines mean squares, which
- Determines *P* values

Be aware of how your ANOVA table is calculated.


## Types of sums of squares

- **Type I**: "sequential", "unweighted" (R's default)
    - ordering of factors in the model matters
    - probably **not** what you want *if you have unbalanced sample sizes*
- **Type II**: main effects allowed to overlap with their interaction terms  (`car::Anova()`)
    - useful if interaction is weak
- **Type III**: "weighted" (`car::Anova()`)
    - each reported effect controls for all the others (including interactions)


## Types of sums of squares

Each type tests subtly different hypotheses.

- Use Type I if you have balanced data
- Type I == Type III if the groups are balanced (ideal situation - you don't have to choose)
- Type III matches the output of `summary(lm())` (so that's nice)
    - The most conservative


## Factorial data

Biomass gain in plants fertilized with either added nitrogen or phosphorous.

![](https://i.imgur.com/5VY9vwE.png){fig-align="center"}


## Factorial data

Biomass gain in plants fertilized with either added nitrogen or phosphorous.

```{r}
#| echo: true

BM <- read_csv("../data/biomass.csv", show_col_types = FALSE)
BM
```


## Unbalanced groups

Randomly drop 20 rows:

```{r}
#| echo: true

set.seed(15)
BM_ub <- BM |> slice_sample(prop = 0.75)
BM_ub |> count(Nitrogen, Phosphorous)
```


## ANOVA Model 1

```{r}
#| echo: true

fm1 <- lm(Biomass ~ Nitrogen * Phosphorous, data = BM_ub)
anova(fm1)
```


## ANOVA Model 2

```{r}
#| echo: true

fm2 <- lm(Biomass ~ Phosphorous * Nitrogen, data = BM_ub)
anova(fm2)
```


## Type III sums of squares

```{r}
#| echo: true

library(car)
Anova(fm1, type = "III")
```


## Type III sums of squares

```{r}
#| echo: true

Anova(fm2, type = "III")
```


## Key points

1. Check your sample sizes within groups
1. Pay attention when you have interaction terms
1. Think about your sums of squares
1. Type II or Type III is likely what you want

## I really want to know more about these Type III sums of squares

Check the course resources page


## These discussions are all specific to sums of squares and variance component estimation.

Alternatives:

- Model Comparisons & Likelihood
- Bayesian Analyses

